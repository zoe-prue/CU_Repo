delta_cq_data <- inner_join(test_data, ref_data_avg, by = "Sample") %>%
mutate(delta_Cq = Cq - avg_ref_Cq)  # Calculate delta_Cq using the average reference Cq
# Check the result
print(delta_cq_data)
# Filter data for "pTRIP JAK1 WT" samples
pTRIP_JAK1_WT <- delta_cq_data %>%
filter(grepl("JAK1 WT 0 IFN", Sample))
pTRIP_JAK1_WT
# Calculate average delta_Cq, handling NA values
average_delta_Cq_ref <- mean(pTRIP_JAK1_WT$delta_Cq, na.rm = TRUE)
# Output the vector of average delta_Cq
average_delta_Cq_ref
# subtract mean delta_cq for your ctrl_sample from all delta_cq values
delta_delta_cq_data <- delta_cq_data %>%
mutate(delta_delta_cq = delta_Cq - average_delta_Cq_ref)
# find the relative concentrations of the target being tested for every sample
rel_conc_data <- delta_delta_cq_data %>%
mutate(rel_conc = 2^(-(delta_delta_cq)))
graph_rel_conc <- function(rel_conc_data, fill_color, probe) {
# Filter out rows with NA values in 'rel_conc'
rel_conc_data <- rel_conc_data[complete.cases(rel_conc_data$rel_conc), ]
# Extract group names without numbers at the end
rel_conc_data$group <- gsub("\\s[0-9]+$", "", rel_conc_data$Sample)
# Make a bar graph with individual data points for each technical replicate
rel_conc_bar <- ggplot(rel_conc_data, aes(x = group, y = rel_conc)) +
theme_classic() +
geom_bar(stat = "identity", fill = fill_color, width = 0.5, color = "black", position = position_dodge(width = 0.7)) +
geom_point(position = position_jitter(width = 0.2), alpha = 0.8, color = "black", size = 1) +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1), axis.title.x = element_blank(), plot.title = element_text(hjust = 0.5)) +
xlab(probe) +
scale_y_continuous(trans = "log10") +
ylab(paste0(probe, "/", "B-ACTIN", " Relative Units")) +
theme(plot.title = element_text(size = 16), axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14))
return(rel_conc_bar)
}
# Generate the plot
rel_conc_bar <- graph_rel_conc(rel_conc_data, fill_color, probe) + ggtitle(paste0(probe, " mRNA"))
rel_conc_bar
View(rel_conc_data)
# Single Graph -------------------------------
# you're welcome to just make one plot and change it up each time!
# here is some simple code to make one plot
# Local variables:
probe = "IFI27" # list of probes of interest
reference = "B-ACTIN" # probe that you're "normalizing" to
ctrl_sample = "JAK1 WT 0 IFN" # sample you're making everything "relative" to
plot_title = " mRNA"
fill_color = "#648FFF"
tidy_qpcr_data <- qpcr_data %>%
mutate(Sample = str_trim(Sample)) %>%
# mutate(Sample = ifelse(Sample == "293T Clone 15", "293T Clone 22", Sample)) %>%
# filter(!Sample %in% c("293T WT", "293T Clone 19", "293T Clone 14", "293T Clone 22")) %>%
filter(str_ends(Sample, "IFNL2") | str_ends(Sample, "0 IFN")) %>%  # Filter targets that end with "IFN a2b" or "0 IFN"
group_by(Sample, Target, Well.Position) %>%
mutate(Cq = as.numeric(Cq)) %>%
select(Well.Position, Sample, Target, Cq)
# create a data table with only Cq values from target being tested (e.g. JAK1)
test_data <- tidy_qpcr_data %>%
filter(Target == probe)
# create a data table with only Cq values from housekeeping gene (e.g. GAPDH)
ref_data <- tidy_qpcr_data %>%
filter(Target == reference) %>%
rename("ref_target" = Target) %>%
rename("ref_Cq" = Cq)
# Group by Sample and calculate the average Cq
test_data <- test_data %>%
group_by(Sample, Target) #%>%
# Step 1: Calculate the average Cq for the reference gene (JAK1) across technical replicates for each Sample
ref_data_avg <- ref_data %>%
group_by(Sample) %>%
summarize(avg_ref_Cq = mean(ref_Cq, na.rm = TRUE))
# Step 2: Join the test data (target gene, e.g., IFI27) with the averaged reference data
delta_cq_data <- inner_join(test_data, ref_data_avg, by = "Sample") %>%
mutate(delta_Cq = Cq - avg_ref_Cq)  # Calculate delta_Cq using the average reference Cq
# Check the result
print(delta_cq_data)
# Filter data for "pTRIP JAK1 WT" samples
pTRIP_JAK1_WT <- delta_cq_data %>%
filter(grepl("JAK1 WT 0 IFN", Sample))
pTRIP_JAK1_WT
# Calculate average delta_Cq, handling NA values
average_delta_Cq_ref <- mean(pTRIP_JAK1_WT$delta_Cq, na.rm = TRUE)
# Output the vector of average delta_Cq
average_delta_Cq_ref
# subtract mean delta_cq for your ctrl_sample from all delta_cq values
delta_delta_cq_data <- delta_cq_data %>%
mutate(delta_delta_cq = delta_Cq - average_delta_Cq_ref)
# find the relative concentrations of the target being tested for every sample
rel_conc_data <- delta_delta_cq_data %>%
mutate(rel_conc = 2^(-(delta_delta_cq)))
graph_rel_conc <- function(rel_conc_data, fill_color, probe) {
# Filter out rows with NA values in 'rel_conc'
rel_conc_data <- rel_conc_data[complete.cases(rel_conc_data$rel_conc), ]
# Extract group names without numbers at the end
rel_conc_data$group <- gsub("\\s[0-9]+$", "", rel_conc_data$Sample)
# Make a bar graph with individual data points for each technical replicate
rel_conc_bar <- ggplot(rel_conc_data, aes(x = group, y = rel_conc)) +
theme_classic() +
geom_bar(stat = "identity", fill = fill_color, width = 0.5, color = "black", position = position_dodge(width = 0.7)) +
geom_point(position = position_jitter(width = 0.2), alpha = 0.8, color = "black", size = 1) +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1), axis.title.x = element_blank(), plot.title = element_text(hjust = 0.5)) +
xlab(probe) +
scale_y_continuous(trans = "log10") +
ylab(paste0(probe, "/", "B-ACTIN", " Relative Units")) +
theme(plot.title = element_text(size = 16), axis.title.x = element_text(size = 14), axis.title.y = element_text(size = 14))
return(rel_conc_bar)
}
# Generate the plot
rel_conc_bar <- graph_rel_conc(rel_conc_data, fill_color, probe) + ggtitle(paste0(probe, " mRNA"))
rel_conc_bar
View(rel_conc_data)
setwd("~/Desktop/CU_coding/RNA-seq/DIY.transcriptomics_scripts")
# load packages----
library(rhdf5) #provides functions for handling hdf5 file formats (kallisto outputs bootstraps in this format)
library(tidyverse) # provides access to Hadley Wickham's collection of R packages for data science, which we will use throughout the course
library(tximport) # package for getting Kallisto results into R
# install packages----
install.packages('tximport')
library(tximport) # package for getting Kallisto results into R
# install packages----
install.packages('tximport')
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("tximport")
library(tximport) # package for getting Kallisto results into R
library(ensembldb) #helps deal with ensembl
install.packages("ensembldb")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("ensembldb")
Yes
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("ensembldb")
library(ensembldb) #helps deal with ensembl
library(EnsDb.Hsapiens.v86) #replace with your organism-specific database package
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("EnsDb.Hsapiens.v86")
library(EnsDb.Hsapiens.v86) #replace with your organism-specific database package
library(EnsDb.Hsapiens.v86) #replace with your organism-specific database package
library(beepr) #just for fun
ssh -T git@github.com
setwd("~/Desktop/CU_coding")
# load packages----
library(rhdf5) #provides functions for handling hdf5 file formats (kallisto outputs bootstraps in this format)
library(tidyverse) # provides access to Hadley Wickham's collection of R packages for data science, which we will use throughout the course
library(tximport) # package for getting Kallisto results into R
library(ensembldb) #helps deal with ensembl
library(EnsDb.Hsapiens.v86) #replace with your organism-specific database package
library(beepr) #just for fun
setRepositories()
install.packages("rhdf5")
library(rhdf5)
library(tidyverse)
library(tximport) # package for getting Kallisto results into R
library(ensembldb) #helps deal with ensembl
library(EnsDb.Hsapiens.v86)
library(beepr)
library(rhdf5) #provides functions for handling hdf5 file formats (kallisto outputs bootstraps in this format)
library(tidyverse) # provides access to Hadley Wickham's collection of R packages for data science, which we will use throughout the course
library(tximport) # package for getting Kallisto results into R
library(ensembldb) #helps deal with ensembl
library(EnsDb.Hsapiens.v86) #replace with your organism-specific database package
library(beepr) #just for fun
library(biomaRt)
library(datapasta)
install.packages("datapasta")
library(datapasta)
setwd("~/Desktop/CU_coding/RNA-seq/DIY.transcriptomics_scripts")
# read in your study design ----
#there are LOTS of ways to read data into R, but the readr package (from tidyverse) is one of the simplest
targets <- read_tsv("studydesign.txt")
View(targets)
# you can easily create file paths to the abundance files generated by Kallisto using the 'file.path' function
path <- file.path(targets$sample, "abundance.tsv") # set file paths to your mapped data
# now check to make sure this path is correct by seeing if the files exist
all(file.exists(path))
setwd("~/Desktop/CU_coding/RNA-seq/DIY.transcriptomics_scripts/mappedReads")
# now check to make sure this path is correct by seeing if the files exist
all(file.exists(path))
# now check to make sure this path is correct by seeing if the files exist
any(file.exists(path))# make sure set directory is DIY.transcriptomics_scripts/mapped_reads
# now check to make sure this path is correct by seeing if the files exist
which(file.exists(path))# make sure set directory is DIY.transcriptomics_scripts/mapped_reads
# read in your study design ----
#there are LOTS of ways to read data into R, but the readr package (from tidyverse) is one of the simplest
targets <- read_tsv("studydesign.txt")
setwd("~/Desktop/CU_coding/RNA-seq/DIY.transcriptomics_scripts")
# read in your study design ----
#there are LOTS of ways to read data into R, but the readr package (from tidyverse) is one of the simplest
targets <- read_tsv("studydesign.txt")
# get annotations using organism-specific package ----
Tx <- transcripts(EnsDb.Hsapiens.v86, columns=c("tx_id", "gene_name"))
Tx <- as_tibble(Tx) # immediately take object and turn into data frame
View(Tx)
#need to change first column name to 'target_id'
Tx <- dplyr::rename(Tx, target_id = tx_id)
#transcript ID needs to be the first column in the dataframe
Tx <- dplyr::select(Tx, "target_id", "gene_name")
listMarts() #default host is ensembl.org, and most current release of mammalian genomes
#choose the 'mart' you want to work with
myMart <- useMart(biomart="ENSEMBL_MART_ENSEMBL")
#take a look at all available datasets within the selected mart
available.datasets <- listDatasets(myMart)
View(available.datasets)
#now grab the ensembl annotations for dog
dog.anno <- useMart(biomart="ENSEMBL_MART_ENSEMBL", dataset = "clfamiliaris_gene_ensembl")
View(dog.anno)
dog.attributes <- listAttributes(dog.anno) # ways I can use filters to parse that
View(dog.attributes)
Tx.dog <- getBM(attributes=c('ensembl_transcript_id_version',
'external_gene_name'),
mart = dog.anno)
View(Tx.dog)
#we need to rename the two columns we just retrieved from biomart
Tx.dog <- dplyr::rename(Tx.dog, target_id = ensembl_transcript_id_version,
gene_name = external_gene_name)
View(myMart)
listMarts() #default host is ensembl.org, and most current release of mammalian genomes
#take a look at all available datasets within the selected mart
available.datasets <- listDatasets(myMart)
View(available.datasets)
View(dog.attributes)
View(Tx.dog)
# import Kallisto transcript counts into R using Tximport ----
# copy the abundance files to the working directory and rename so that each sample has a unique name
Txi_gene <- tximport(path,
type = "kallisto",
tx2gene = Tx, # our database
txOut = FALSE, # TRUE = output transcripts, FALSE = gene data
countsFromAbundance = "lengthScaledTPM",
ignoreTxVersion = TRUE)
setwd("~/Desktop/CU_coding/RNA-seq/DIY.transcriptomics_scripts/mappedReads")
# import Kallisto transcript counts into R using Tximport ----
# copy the abundance files to the working directory and rename so that each sample has a unique name
Txi_gene <- tximport(path,
type = "kallisto",
tx2gene = Tx, # our database
txOut = FALSE, # TRUE = output transcripts, FALSE = gene data
countsFromAbundance = "lengthScaledTPM",
ignoreTxVersion = TRUE)
View(Txi_gene)
View(Txi_gene)
View(Txi_gene)
beep(sound = 6)
#take a look at the type of object you just created
class(Txi_gene)
names(Txi_gene)
print("Step 1 complete!")
setwd("~/Desktop/CU_coding/RNA-seq/DIY.transcriptomics_scripts")
install.packages("edgeR")
install.packages("matrixStats")
library(cowplot)
# Load packages -----
library(tidyverse) # already know about this from Step 1 script
library(edgeR) # well known package for differential expression analysis, but we only use for the DGEList object and for normalization methods
library(matrixStats) # let's us easily calculate stats on rows or columns of a data matrix
library(cowplot) # allows you to combine multiple plots in one figure
View(Txi_gene)
# Load packages -----
library(tidyverse) # already know about this from Step 1 script
library(edgeR) # well known package for differential expression analysis, but we only use for the DGEList object and for normalization methods
library(matrixStats) # lets us easily calculate stats on rows or columns of a data matrix
library(cowplot) # allows you to combine multiple plots in one figure
setwd("~/Desktop/CU_coding/RNA-seq/DIY.transcriptomics_scripts")
# the essentials ----
# this chunk contains the minimal essential code from this script. Simply uncomment the lines below and run the code.
library(tidyverse) # provides access to Hadley Wickham's collection of R packages for data science, which we will use throughout the course
library(tximport) # package for getting Kallisto results into R
library(ensembldb) #helps deal with ensembl
library(EnsDb.Hsapiens.v86) #replace with your organism-specific database package
View(Txi_gene)
View(Txi_gene)
View(Txi_gene)
library(cowplot) # allows you to combine multiple plots in one figure
# Examine your data up to this point ----
# any list object can be examined using $, like a data frame
myTPM <- Txi_gene$abundance
View(myTPM)
myCounts <- Txi_gene$counts
View(myCounts)
colSums(myTPM)
colSums(myCounts)
# capture sample labels from the study design file that you worked with and saved as 'targets' in step 1
targets # study design file is a tibble
sampleLabels <- targets$sample
# Generate summary stats for your data ----
# 1st, calculate summary stats for each transcript or gene, and add these to your data matrix
# then use the base R function 'transform' to modify the data matrix (equivalent of Excel's '=')
# then we use the 'rowSds', 'rowMeans' and 'rowMedians' functions from the matrixStats package
# calculated new columns based on existing columns
myTPM.stats <- transform(myTPM,
SD=rowSds(myTPM),
AVG=rowMeans(myTPM),
MED=rowMedians(myTPM))
# look at what you created
head(myTPM.stats)
View(myTPM.stats)
# Create your first plot using ggplot2 ----
# produce a scatter plot of the transformed data
ggplot(myTPM.stats) +
aes(x = SD, y = MED) +
geom_point(shape=25, size=3)
# Let's expand on the plot above a bit more and take a look at each 'layer' of the ggplot code
ggplot(myTPM.stats) +
aes(x = SD, y = MED) +
geom_point(shape=16, size=2) +
geom_smooth(method=lm) +
geom_hex(show.legend = FALSE) +
labs(y="Median", x = "Standard deviation",
title="Transcripts per million (TPM)",
subtitle="unfiltered, non-normalized data",
caption="DIYtranscriptomics - Spring 2020") +
theme_classic() +
theme_dark() +
theme_bw()
# Make a DGElist from your counts, and plot ----
# DGEList of raw counts
myDGEList <- DGEList(myCounts)
View(myDGEList)
# take a look at the DGEList object
myDGEList
#DEGList objects are a good R data file to consider saving to you working directory
save(myDGEList, file = "myDGEList")
#Saved DGEList objects can be easily shared and loaded into an R environment
load(file = "myDGEList")
# use the 'cpm' function from EdgeR to get counts per million
cpm <- edgeR::cpm(myDGEList) # counts per million
colSums(cpm)
log2.cpm <- edgeR::cpm(myDGEList, log=TRUE) # log=TRUE converts to log2 automatically, can do log10
# 'coerce' your data matrix to a dataframe so that you can use tidyverse tools on it
log2.cpm.df <- as_tibble(log2.cpm, rownames = "geneID") # drops rownames (thinks it should be another column in data) so we get it back
log2.cpm.df
# add your sample names to this dataframe (we lost these when we read our data in with tximport) top row!
colnames(log2.cpm.df) <- c("geneID", sampleLabels)
log2.cpm.df
# let's look at the impact of pivoting the data
log2.cpm.df.pivot
# Tidy data philosophy:
# each variable forms a column
# each observation forms a row
# each type of observational unit forms a table
# e.g. if every variable formed a column (treatment 1, treatment 2, etc.) then the data frame is very long
# pivot longer so there is a "treatment" column with the treatment numbers underneath as the rows
# use the tidy package to 'pivot' your dataframe (from wide to long)
log2.cpm.df.pivot <- pivot_longer(log2.cpm.df, # dataframe to be pivoted
cols = HS01:CL13, # column names to be stored as a SINGLE variable
names_to = "samples", # name of that new variable (column)
values_to = "expression") # name of new variable (column) storing all the values (data)
# let's look at the impact of pivoting the data
log2.cpm.df.pivot
# not it is easy to plot this pivoted data
ggplot(log2.cpm.df.pivot) +
aes(x=samples, y=expression, fill=samples) +
geom_violin(trim = FALSE, show.legend = FALSE) +
stat_summary(fun = "median",
geom = "point",
shape = 95,
size = 10,
color = "black",
show.legend = FALSE) +
labs(y="log2 expression", x = "sample",
title="Log2 Counts per Million (CPM)",
subtitle="unfiltered, non-normalized",
caption=paste0("produced on ", Sys.time())) +
theme_bw()
# not it is easy to plot this pivoted data
ggplot(log2.cpm.df.pivot) +
aes(x=samples, y=expression, fill=samples) +
geom_violin(trim = FALSE, show.legend = FALSE) +
stat_summary(fun = "median",
geom = "point",
shape = 95,
size = 10,
color = "black",
show.legend = FALSE) +
labs(y="log2 expression", x = "sample",
title="Log2 Counts per Million (CPM)",
subtitle="unfiltered, non-normalized",
caption=paste0("produced on ", Sys.time())) +
theme_bw() +
coord_flip()
# Filter your data ----
#first, take a look at how many genes or transcripts have no read counts at all
table(rowSums(myDGEList$counts==0)==10) # how many samples had zero counts
# The line below is important! This is where the filtering starts
# Be sure to adjust this cutoff for the number of samples in the smallest group of comparison.
keepers <- rowSums(cpm>1)>=5 # how many genes had counts per million that were greater than 1 and greater than or equal to 5 samples
# 5 samples bc theres 5 healthy and 5 sick patients
# now use base R's simple subsetting method to filter your DGEList based on the logical produced above
# [rows,columns]
myDGEList.filtered <- myDGEList[keepers,]
View(myDGEList.filtered)
dim(myDGEList.filtered)
log2.cpm.filtered <- edgeR::cpm(myDGEList.filtered, log=TRUE)
log2.cpm.filtered.df <- as_tibble(log2.cpm.filtered, rownames = "geneID")
colnames(log2.cpm.filtered.df) <- c("geneID", sampleLabels)
# pivot this FILTERED data, just as you did earlier
log2.cpm.filtered.df.pivot <- pivot_longer(log2.cpm.filtered.df, # dataframe to be pivoted
cols = -1, # column names to be stored as a SINGLE variable
names_to = "samples", # name of that new variable (column)
values_to = "expression") # name of new variable (column) storing all the values (data)
ggplot(log2.cpm.filtered.df.pivot) +
aes(x=samples, y=expression, fill=samples) +
geom_violin(trim = FALSE, show.legend = FALSE) +
stat_summary(fun = "median",
geom = "point",
shape = 95,
size = 10,
color = "black",
show.legend = FALSE) +
labs(y="log2 expression", x = "sample",
title="Log2 Counts per Million (CPM)",
subtitle="filtered, non-normalized",
caption=paste0("produced on ", Sys.time())) +
theme_bw()
# Normalize your data ----
myDGEList.filtered.norm <- calcNormFactors(myDGEList.filtered, method = "TMM")
View(myDGEList.filtered.norm)
# use the 'cpm' function from EdgeR to get counts per million from your normalized data
log2.cpm.filtered.norm <- edgeR::cpm(myDGEList.filtered.norm, log=TRUE)
log2.cpm.filtered.norm.df <- as_tibble(log2.cpm.filtered.norm, rownames = "geneID")
colnames(log2.cpm.filtered.norm.df) <- c("geneID", sampleLabels)
# pivot this NORMALIZED data, just as you did earlier
log2.cpm.filtered.norm.df.pivot <- pivot_longer(log2.cpm.filtered.norm.df, # dataframe to be pivoted
cols = -1, # column names to be stored as a SINGLE variable
names_to = "samples", # name of that new variable (column)
values_to = "expression") # name of new variable (column) storing all the values (data)
ggplot(log2.cpm.filtered.norm.df.pivot) +
aes(x=samples, y=expression, fill=samples) +
geom_violin(trim = FALSE, show.legend = FALSE) +
stat_summary(fun = "median",
geom = "point",
shape = 95,
size = 10,
color = "black",
show.legend = FALSE) +
labs(y="log2 expression", x = "sample",
title="Log2 Counts per Million (CPM)",
subtitle="filtered, TMM normalized",
caption=paste0("produced on ", Sys.time())) +
theme_bw()
# what if we wanted to put all three violin plots together?
# go back and assign each plot to a variable (rather than printing to the plots viewer)
# here we assigned the last 3 plots to p1, p2 and p3
# we'll use the 'plot_grid' function from the cowplot package to put these together in a figure
plot_grid(p1, p2, p3, labels = c('A', 'B', 'C'), label_size = 12)
# not it is easy to plot this pivoted data
p1 <- ggplot(log2.cpm.df.pivot) +
aes(x=samples, y=expression, fill=samples) +
geom_violin(trim = FALSE, show.legend = FALSE) +
stat_summary(fun = "median",
geom = "point",
shape = 95,
size = 10,
color = "black",
show.legend = FALSE) +
labs(y="log2 expression", x = "sample",
title="Log2 Counts per Million (CPM)",
subtitle="unfiltered, non-normalized",
caption=paste0("produced on ", Sys.time())) +
theme_bw() +
coord_flip()
p2 <- ggplot(log2.cpm.filtered.df.pivot) +
aes(x=samples, y=expression, fill=samples) +
geom_violin(trim = FALSE, show.legend = FALSE) +
stat_summary(fun = "median",
geom = "point",
shape = 95,
size = 10,
color = "black",
show.legend = FALSE) +
labs(y="log2 expression", x = "sample",
title="Log2 Counts per Million (CPM)",
subtitle="filtered, non-normalized",
caption=paste0("produced on ", Sys.time())) +
theme_bw()
p3 <- ggplot(log2.cpm.filtered.norm.df.pivot) +
aes(x=samples, y=expression, fill=samples) +
geom_violin(trim = FALSE, show.legend = FALSE) +
stat_summary(fun = "median",
geom = "point",
shape = 95,
size = 10,
color = "black",
show.legend = FALSE) +
labs(y="log2 expression", x = "sample",
title="Log2 Counts per Million (CPM)",
subtitle="filtered, TMM normalized",
caption=paste0("produced on ", Sys.time())) +
theme_bw()
# what if we wanted to put all three violin plots together?
# go back and assign each plot to a variable (rather than printing to the plots viewer)
# here we assigned the last 3 plots to p1, p2 and p3
# we'll use the 'plot_grid' function from the cowplot package to put these together in a figure
plot_grid(p1, p2, p3, labels = c('A', 'B', 'C'), label_size = 12)
print("Step 2 complete!")
setwd("~/Desktop/CU_coding/RNA-seq/DGE_RNAseq")
View(Txi_gene)
#take a look at the type of object you just created
class(Txi_gene)
names(Txi_gene)
head(abundance.tsv)
setwd("~/Desktop/CU_coding/RNA-seq/DIY.transcriptomics_scripts/mappedReads/CL08")
head(abundance.tsv)
head("abundance.tsv")
view("abundance.tsv")
head("abundance.tsv")
list("abundance.tsv")
View(Tx)
View(myDGEList)
